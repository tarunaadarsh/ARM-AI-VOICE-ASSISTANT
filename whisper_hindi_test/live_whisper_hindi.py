import sounddevice as sd
import numpy as np
import whisper
import time
from datetime import datetime
import sys

# ================== CONFIG ==================
DEVICE_INDEX = 9            # Your microphone device
SAMPLE_RATE = 48000         # MUST match mic default
CHANNELS = 1
RECORD_SECONDS = 4          # Each speech chunk
SILENCE_THRESHOLD = 0.01    # Adjust if needed
MODEL_SIZE = "small"        # tiny / base / small
STOP_WORDS = ["рдмрдВрдж", "рд░реБрдХреЛ", "stop"]

# Local static info (offline)
LOCATION = "рдХреБрдиреНрджреНрд░рдереБрд░, рдЪреЗрдиреНрдирдИ"
TEMPERATURE = "32┬░C"
WEATHER = "рдзреВрдк"
# ============================================

print("ЁЯУж Loading Whisper Model...")
model = whisper.load_model(MODEL_SIZE)

print("\nЁЯОд LIVE HINDI VOICE ASSISTANT")
print("ЁЯЫС CTRL + C рджрдмрд╛рдХрд░ рдмрдВрдж рдХрд░реЗрдВ\n")


def record_audio():
    """Record fixed-duration audio chunk"""
    audio = sd.rec(
        int(RECORD_SECONDS * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="float32",
        device=DEVICE_INDEX
    )
    sd.wait()
    return audio.flatten()


def is_silence(audio):
    """Detect silence to avoid useless inference"""
    return np.max(np.abs(audio)) < SILENCE_THRESHOLD


def chatbot_reply(text):
    text = text.strip()

    # EXIT
    if any(w in text for w in STOP_WORDS):
        return "рдареАрдХ рд╣реИ, рдореИрдВ рдмрдВрдж рд╣реЛ рд░рд╣рд╛ рд╣реВрдБ", True

    # TIME
    if any(w in text for w in ["рд╕рдордп", "рдЯрд╛рдЗрдо", "clock"]):
        now = datetime.now().strftime("%H:%M")
        return f"рдЕрднреА рд╕рдордп {now} рд╣реИ", False

    # DATE
    if any(w in text for w in ["рддрд╛рд░реАрдЦ", "рджрд┐рди", "рдбреЗрдЯ"]):
        today = datetime.now().strftime("%d-%m-%Y")
        return f"рдЖрдЬ рдХреА рддрд╛рд░реАрдЦ {today} рд╣реИ", False

    # LOCATION
    if any(w in text for w in ["рдореИрдВ рдХрд╣рд╛рдБ", "рдореЗрд░реА рдЬрдЧрд╣", "рд▓реЛрдХреЗрд╢рди"]):
        return f"рдЖрдк {LOCATION} рдореЗрдВ рд╣реИрдВ", False

    # WEATHER
    if "рдореМрд╕рдо" in text or "рддрд╛рдкрдорд╛рди" in text:
        return f"{LOCATION} рдореЗрдВ рддрд╛рдкрдорд╛рди {TEMPERATURE} рд╣реИ рдФрд░ рдореМрд╕рдо {WEATHER} рд╣реИ", False

    # IDENTITY
    if any(w in text for w in ["рддреБрдо рдХреМрди", "рдЖрдк рдХреМрди", "рддреБрдо рдХреНрдпрд╛ рд╣реЛ"]):
        return "рдореИрдВ рдПрдХ рдСрдлрд▓рд╛рдЗрди рд╣рд┐рдВрджреА рд╡реЙрдЗрд╕ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рд╣реВрдБ, рдкреВрд░реА рддрд░рд╣ рдкреНрд░рд╛рдЗрд╡реЗрдЯ", False

    # HELP
    if "рдорджрдж" in text or "рдХреНрдпрд╛ рдХрд░ рд╕рдХрддреЗ" in text:
        return (
            "рдореИрдВ рд╕рдордп, рддрд╛рд░реАрдЦ, рдореМрд╕рдо, рд▓реЛрдХреЗрд╢рди рдФрд░ рд╕реНрдерд╛рдиреАрдп рдЬрд╛рдирдХрд╛рд░реА рдмрддрд╛ рд╕рдХрддрд╛ рд╣реВрдБ",
            False
        )

    return "рдорд╛рдлрд╝ рдХреАрдЬрд┐рдП, рдореИрдВ рдпрд╣ рд╕рдордЭ рдирд╣реАрдВ рдкрд╛рдпрд╛", False


# ================== MAIN LOOP ==================
try:
    while True:
        print("ЁЯОЩя╕П Listening...")
        audio = record_audio()

        if is_silence(audio):
            print("ЁЯдл Silence detected, skipping...\n")
            continue

        result = model.transcribe(
            audio,
            language="hi",
            fp16=False
        )

        text = result["text"].strip()

        if not text:
            print("ЁЯдл Empty speech\n")
            continue

        print(f"ЁЯзС User : {text}")

        reply, should_exit = chatbot_reply(text)
        print(f"ЁЯдЦ Bot  : {reply}\n")

        if should_exit:
            break

except KeyboardInterrupt:
    print("\nЁЯЫС Assistant interrupted by user")

finally:
    print("тЬЕ Assistant stopped safely")
    sys.exit(0)
